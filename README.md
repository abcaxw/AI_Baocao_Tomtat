# ğŸ¤– AI Document Summarizer API

Há»‡ thá»‘ng AI tÃ³m táº¯t vÄƒn báº£n thÃ´ng minh, há»— trá»£ nhiá»u Ä‘á»‹nh dáº¡ng file (PDF, DOCX, XLSX, TXT).

## âœ¨ TÃ­nh nÄƒng

- âœ… Äá»c nhiá»u loáº¡i file: PDF, DOCX, XLSX, TXT
- ğŸ§  AI thÃ´ng minh vá»›i OpenAI hoáº·c Claude
- ğŸ“Š Tá»± Ä‘á»™ng phÃ¢n loáº¡i cÃ¢u há»i vÃ  format output
- ğŸ¯ 10+ loáº¡i cÃ¢u há»i Ä‘Æ°á»£c há»— trá»£
- âš¡ API nhanh vá»›i FastAPI
- ğŸ“¦ Xá»­ lÃ½ batch nhiá»u file

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone hoáº·c táº¡o project

```bash
mkdir doc_summarizer
cd doc_summarizer
```

### 2. Táº¡o cáº¥u trÃºc thÆ° má»¥c

```
doc_summarizer/
â”œâ”€â”€ main.py
â”œâ”€â”€ parsers.py
â”œâ”€â”€ classifier.py
â”œâ”€â”€ summarizer.py
â”œâ”€â”€ formatters.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ temp_uploads/
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 4. Cáº¥u hÃ¬nh API Key

Táº¡o file `.env`:

```bash
# DÃ¹ng OpenAI
AI_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Hoáº·c dÃ¹ng Claude
# AI_PROVIDER=claude
# ANTHROPIC_API_KEY=sk-ant-your-key-here
```

### 5. Cháº¡y server

```bash
python main.py
```

Hoáº·c:

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Server cháº¡y táº¡i: http://localhost:8000

## ğŸ“– Sá»­ dá»¥ng API

### 1. Kiá»ƒm tra API

```bash
curl http://localhost:8000/health
```

### 2. TÃ³m táº¯t vÄƒn báº£n

**Python:**

```python
import requests

url = "http://localhost:8000/summarize"

files = {
    'file': open('document.pdf', 'rb')
}

data = {
    'question': 'TÃ³m táº¯t tÃ i liá»‡u má»™t cÃ¡ch ngáº¯n gá»n',
    'question_type': 'tom_tat'  # Optional
}

response = requests.post(url, files=files, data=data)
result = response.json()

print(result['answer'])
```

**cURL:**

```bash
curl -X POST "http://localhost:8000/summarize" \
  -F "file=@document.pdf" \
  -F "question=TÃ³m táº¯t tÃ i liá»‡u" \
  -F "question_type=tom_tat"
```

**JavaScript:**

```javascript
const formData = new FormData();
formData.append('file', fileInput.files[0]);
formData.append('question', 'TÃ³m táº¯t tÃ i liá»‡u');

const response = await fetch('http://localhost:8000/summarize', {
  method: 'POST',
  body: formData
});

const result = await response.json();
console.log(result.answer);
```

### 3. Batch processing

```python
import requests
import json

url = "http://localhost:8000/batch-summarize"

files = [
    ('files', open('doc1.pdf', 'rb')),
    ('files', open('doc2.docx', 'rb'))
]

questions = json.dumps([
    {"question": "TÃ³m táº¯t tÃ i liá»‡u 1"},
    {"question": "Má»¥c tiÃªu cá»§a tÃ i liá»‡u 2", "question_type": "muc_tieu"}
])

data = {'questions': questions}

response = requests.post(url, files=files, data=data)
results = response.json()
```

## ğŸ¯ CÃ¡c loáº¡i cÃ¢u há»i Ä‘Æ°á»£c há»— trá»£

| Loáº¡i | Tá»« khÃ³a | Format Output |
|------|---------|---------------|
| **tom_tat** | tÃ³m táº¯t, tá»•ng há»£p | Sections + Bullets |
| **muc_tieu** | má»¥c tiÃªu, Ä‘á»‹nh hÆ°á»›ng | Table + Metrics |
| **cach_thuc_hien** | lÃ m tháº¿ nÃ o, cÃ¡ch thá»±c hiá»‡n | Steps + Sub-bullets |
| **ke_hoach** | káº¿ hoáº¡ch, lá»™ trÃ¬nh | Table with timeline |
| **kho_khan** | khÃ³ khÄƒn, thÃ¡ch thá»©c | Sections + Examples |
| **ket_qua** | káº¿t quáº£, thÃ nh tÃ­ch | Metrics + Analysis |
| **so_sanh** | so sÃ¡nh, xáº¿p háº¡ng | Comparison table |
| **goi_y** | gá»£i Ã½, Ä‘á» xuáº¥t | Action items |
| **hieu_qua** | hiá»‡u quáº£, tÃ¡c Ä‘á»™ng | Analysis + Metrics |
| **phuong_an** | phÆ°Æ¡ng Ã¡n, giáº£i phÃ¡p | Options + Comparison |

## ğŸ“‹ Response Format

```json
{
  "success": true,
  "document_name": "report.pdf",
  "question": "TÃ³m táº¯t tÃ i liá»‡u",
  "question_type": "tom_tat",
  "answer": "### TÃ“M Táº®T\n\nI. Pháº§n 1...",
  "format_info": {
    "structure_type": "hierarchical",
    "has_tables": false,
    "sections": "3-6"
  },
  "metadata": {
    "file_size": 1048576,
    "content_length": 5000,
    "answer_length": 1200
  }
}
```

## ğŸ”§ Cáº¥u hÃ¬nh nÃ¢ng cao

### Thay Ä‘á»•i model

File `.env`:
```bash
OPENAI_MODEL=gpt-4  # DÃ¹ng GPT-4 cho cháº¥t lÆ°á»£ng cao hÆ¡n
MAX_TOKENS=8000     # TÄƒng Ä‘á»™ dÃ i output
```

### Custom format

Chá»‰nh sá»­a `classifier.py` Ä‘á»ƒ thÃªm loáº¡i cÃ¢u há»i má»›i:

```python
self.patterns["custom_type"] = [
    r"pattern1",
    r"pattern2"
]
```

## ğŸ› Debug

### Báº­t logging

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Test tá»«ng module

```bash
# Test parser
python parsers.py

# Test classifier
python classifier.py

# Test summarizer
python summarizer.py
```

## ğŸ“Š Performance

- PDF (10 trang): ~5-10 giÃ¢y
- DOCX (20 trang): ~8-15 giÃ¢y
- XLSX (nhiá»u sheet): ~10-20 giÃ¢y

TÃ¹y thuá»™c vÃ o:
- Model AI Ä‘Æ°á»£c dÃ¹ng
- Äá»™ dÃ i tÃ i liá»‡u
- Äá»™ phá»©c táº¡p cÃ¢u há»i

## ğŸ”’ Báº£o máº­t

- âš ï¸ KhÃ´ng lÆ°u file upload vÄ©nh viá»…n
- ğŸ” API key nÃªn dÃ¹ng environment variables
- ğŸš« ThÃªm authentication náº¿u deploy public
- ğŸ“ Rate limiting cho production

## ğŸš¢ Deploy

### Docker

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
docker build -t doc-summarizer .
docker run -p 8000:8000 --env-file .env doc-summarizer
```

### Cloud (Railway, Render, etc.)

1. Push code lÃªn GitHub
2. Connect repository
3. Add environment variables
4. Deploy!

## ğŸ“ Support

CÃ³ váº¥n Ä‘á»? Kiá»ƒm tra:

1. âœ… API key Ä‘Ãºng chÆ°a?
2. âœ… File format cÃ³ Ä‘Æ°á»£c há»— trá»£?
3. âœ… Dependencies Ä‘Ã£ cÃ i Ä‘á»§?
4. âœ… Port 8000 cÃ³ bá»‹ chiáº¿m?

## ğŸ“„ License

MIT License - Free to use!